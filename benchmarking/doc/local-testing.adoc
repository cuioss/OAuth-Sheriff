= Local Testing Guide
:source-highlighter: highlight.js

== Quick Start

To view benchmark results locally after running benchmarks:

=== Step 1: Run Benchmarks

[source,bash]
----
# Run micro benchmarks
./mvnw verify -pl benchmarking/benchmark-library -Pbenchmark

# Run WRK load testing benchmarks
./mvnw verify -pl benchmarking/benchmark-integration-wrk -Pbenchmark
----

=== Step 2: Generate Reports

Generate comprehensive HTML reports from benchmark results:

[source,bash]
----
cd benchmarking/cui-benchmarking-common
mvn test -Dtest=LocalReportGeneratorTest
----

This creates reports in `benchmarking/cui-benchmarking-common/target/benchmark-reports-preview/`.

=== Step 3: Serve Results Locally

The serve-reports.sh script can serve different benchmark results:

[source,bash]
----
cd benchmarking/scripts

# Serve common preview reports (default)
./serve-reports.sh
# or explicitly:
./serve-reports.sh common

# Serve library benchmark raw results
./serve-reports.sh library

# Serve WRK load testing raw results
./serve-reports.sh wrk

# Specify both module and port
./serve-reports.sh library 8081
./serve-reports.sh wrk 8082

# To stop the server:
./serve-reports.sh stop
----

By default, the script serves from `benchmarking/cui-benchmarking-common/target/benchmark-reports-preview/`.

=== Step 4: View Results

Open your browser to http://localhost:8080 to view the comprehensive reports including:
- Performance overview dashboards
- Interactive charts and trends
- Detailed benchmark tables
- Performance badges and metrics

== Generated Artifacts Location

The serve-reports.sh script can serve from three different locations:

=== Module: common (default)
* **Directory**: `benchmarking/cui-benchmarking-common/target/benchmark-reports-preview/`
* **Content**: Processed preview reports with HTML visualizations, badges, and interactive dashboards
* **Generated by**: LocalReportGeneratorTest processing raw benchmark results

=== Module: library
* **Directory**: `benchmarking/benchmark-library/target/benchmark-results/`
* **Content**: Raw micro benchmark results, JMH output, metrics JSON
* **Generated by**: Running library benchmarks with `-Pbenchmark`

=== Module: wrk
* **Directory**: `benchmarking/benchmark-integration-wrk/target/benchmark-results/`
* **Content**: Raw WRK load testing results, Prometheus metrics, WRK output
* **Generated by**: Running WRK benchmarks with `-Pbenchmark`

== Manual HTTP Server Options

If you want to bypass the serve-reports.sh script, you can serve the preview reports directly:

[source,bash]
----
# Serve the preview reports
cd benchmarking/cui-benchmarking-common/target/benchmark-reports-preview
python3 -m http.server 8080
----

Alternative servers:

[source,bash]
----
# Node.js (requires http-server)
npx http-server -p 8080

# PHP
php -S localhost:8080

# Ruby
ruby -run -ehttpd . -p8080
----

== Why HTTP Server?

Modern browsers enforce strict security policies that prevent JavaScript from loading local files directly (CORS policy). An HTTP server provides the proper protocol and headers for the templates to function correctly.

== Viewing Specific Components

The generated artifacts include:

* **Performance Badges** - View in `badges/` directory
* **Metrics Data** - JSON files in `data/` directory  
* **Summary Report** - `benchmark-summary.json` with quality gates
* **Raw Results** - JMH output in `*-benchmark-result.json`

== Troubleshooting

=== No Results Generated

- Ensure benchmarks ran successfully
- Check for compilation errors
- Verify the correct Maven profile was used

=== "Failed to fetch" Errors

- Make sure you're accessing via `http://localhost:8080`, not `file://`
- Check that the HTTP server is running

=== 404 Errors

- Verify benchmark results were generated
- Check the correct directory is being served
- Ensure artifacts exist in `target/benchmark-results/`

=== Port Already in Use

- Try a different port number
- Check for other running servers: `lsof -i :8080`

== Development Tips

=== Quick Workflow Examples

[source,bash]
----
# 1. Run library benchmarks and view raw results
./mvnw verify -pl benchmarking/benchmark-library -Pbenchmark \
  -Djmh.iterations=1 -Djmh.warmupIterations=1
cd benchmarking/scripts && ./serve-reports.sh library

# 2. Run WRK benchmarks and view raw results
./mvnw verify -pl benchmarking/benchmark-integration-wrk -Pbenchmark
cd benchmarking/scripts && ./serve-reports.sh wrk

# 3. Generate and view comprehensive preview reports
cd benchmarking/cui-benchmarking-common
mvn test -Dtest=LocalReportGeneratorTest
cd ../scripts && ./serve-reports.sh common

# 4. Run multiple servers for comparison
./serve-reports.sh common 8080 &  # Preview reports
./serve-reports.sh library 8081 & # Library raw results
./serve-reports.sh wrk 8082 &     # WRK raw results
----