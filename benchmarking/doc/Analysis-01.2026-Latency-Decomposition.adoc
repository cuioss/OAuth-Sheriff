= Latency Decomposition — Ablation Study
:toc: left
:toclevels: 3
:toc-title: Table of Contents
:sectnums:
:source-highlighter: highlight.js

Companion document to link:Analysis-01.2026-Integration.adoc[JWT Validation Performance Analysis].

== Overview

A **mock JWT endpoint** (`/mock-jwt/validate`) was created to directly measure the latency decomposition. The mock endpoint replicates the JWT endpoint's full HTTP processing path — CDI injection, `HttpServletRequestResolver.resolveHeaderMap()`, `Authorization` header extraction, and `ValidationResponse` JSON serialization — but **skips the actual JWT library validation** (`tokenValidator.createAccessToken()`). This turns the inferred decomposition into a measured one.

An **ablation study** further decomposes the gap between the health endpoint and mock JWT endpoint by progressively adding processing layers. Three additional endpoints isolate individual cost components:

[cols="1,2,3,3", options="header"]
|===
|Variant
|Path
|What it does
|What it isolates

|Health (existing)
|`GET /q/health/live`
|SmallRye Health, minimal JSON
|Shared infrastructure baseline

|**A: Bare Baseline** (new class)
|`POST /mock-jwt-bare/baseline`
|Zero CDI injection, pre-built `ValidationResponse`
|JAX-RS + `@RunOnVirtualThread` + Jackson — **without any CDI beans**

|**B: JAX-RS Baseline** (new method)
|`POST /mock-jwt/baseline`
|Same as A but in CDI-injected class
|Confirms `@ApplicationScoped` injection has zero per-request cost (A vs B)

|**C: Header Only** (new method)
|`POST /mock-jwt/header-only`
|Calls `resolveHeaderMap()`, returns pre-built response
|**Vert.x context resolution cost** (C minus B)

|Mock JWT (existing)
|`POST /mock-jwt/validate`
|resolveHeaderMap() + header parsing + HashMap construction
|**Authorization parsing + HashMap allocation** (Mock minus C)

|JWT (existing)
|`POST /jwt/validate`
|Full JWT validation
|CDI producer chain + JWT validation
|===

All variants use **POST with Authorization header** (same WRK Lua script pattern) so differences are purely server-side.

== Ablation Study Results (50 connections)

[cols="2,2,2,2,2", options="header"]
|===
|Endpoint
|P50 (ms)
|P90 (ms)
|P99 (ms)
|Throughput

|Health (`/q/health/live`)
|0.510
|2.09
|6.59
|64,947 ops/s

|**B: JAX-RS Baseline** (`/mock-jwt/baseline`)
|**0.784**
|**2.91**
|**8.83**
|**49,154 ops/s**

|**C: Header Only** (`/mock-jwt/header-only`)
|**0.820**
|**2.94**
|**8.46**
|**47,176 ops/s**

|**Mock JWT** (`/mock-jwt/validate`)
|**0.823**
|**3.01**
|**8.88**
|**46,800 ops/s**

|**A: Bare Baseline** (`/mock-jwt-bare/baseline`)
|**0.870**
|**3.63**
|**11.51**
|**43,191 ops/s**

|JWT (`/jwt/validate`)
|1.91
|4.29
|12.03
|23,051 ops/s
|===

NOTE: All six endpoints benchmarked in the same run. Variant A ran last (6th benchmark), which explains its slightly higher latency compared to B — benchmark ordering effects, not CDI overhead.

== Five-Layer Decomposition

The ablation study decomposes the full JWT P50 latency (1.91ms) into measured layers. Each layer isolates a specific processing cost by comparing adjacent ablation variants.

[cols="3,2,2,2", options="header"]
|===
|Layer
|Latency (P50)
|Percentage
|How Measured

|**1. Shared infrastructure** (Docker, TLS, HTTP/2, Quarkus GET routing)
|0.510ms
|26.7%
|Health endpoint

|**2. JAX-RS POST routing + `@RunOnVirtualThread` + Jackson serialization**
|0.274ms
|14.3%
|B minus Health (0.784 − 0.510)

|**3. CDI `@ApplicationScoped` injection overhead**
|~0ms
|~0%
|A vs B comparison (see below)

|**4. Vert.x context resolution** (`resolveHeaderMap()`)
|0.036ms
|1.9%
|C minus B (0.820 − 0.784)

|**5. Authorization parsing + HashMap construction**
|0.003ms
|0.2%
|Mock JWT minus C (0.823 − 0.820)

|**6. CDI producer chain + JWT validation**
|1.087ms
|56.9%
|JWT minus Mock JWT (1.91 − 0.823)
|===

**Total JWT P50**: 1.91ms = 0.510 + 0.274 + 0.036 + 0.003 + 1.087 = 1.91ms

=== Key Findings

**JAX-RS POST routing is the dominant mock-to-health gap component.** The 0.274ms cost of JAX-RS POST routing + `@RunOnVirtualThread` dispatch + Jackson serialization accounts for 87% of the 0.313ms gap between the health and mock JWT endpoints. This is expected — POST requests with JSON serialization of a `ValidationResponse` record require more processing than the SmallRye Health GET endpoint.

**CDI `@ApplicationScoped` injection has zero per-request cost.** Variant A (zero CDI, 0.870ms) was actually _slower_ than variant B (CDI-injected, 0.784ms) by 0.086ms. Since CDI overhead would make B slower, this confirms `@ApplicationScoped` beans are resolved at startup, not per request. The 0.086ms difference is attributable to benchmark ordering (A ran 6th, B ran 4th) and normal variance.

**Vert.x context resolution is minimal.** The `resolveHeaderMap()` call adds only 0.036ms (36µs), a small cost for accessing the Vert.x request context and extracting HTTP headers into a `Map<String, List<String>>`.

**Authorization parsing is negligible.** The full header parsing pipeline — extracting the `authorization` key, checking the `Bearer ` prefix, substring extraction, and `HashMap` construction — costs only 0.003ms (3µs), effectively free.

**CDI producer chain + JWT validation remains the dominant cost at 57%.** The 1.087ms gap between JWT and mock JWT (consistent with the previous measurement of 1.117ms) confirms that `Instance<BearerTokenResult>` proxy resolution, `@Timed` instrumentation, and concurrent JWT validation are the primary optimization targets.

=== Ablation Variant Descriptions

* **A: Bare Baseline** (`/mock-jwt-bare/baseline`) — Separate JAX-RS class with zero CDI constructor injection. Returns a pre-built `ValidationResponse`. Isolates JAX-RS + `@RunOnVirtualThread` + Jackson without any CDI beans.
* **B: JAX-RS Baseline** (`/mock-jwt/baseline`) — Same behavior as A, but in the CDI-injected `MockJwtValidationEndpoint` class. Comparing A vs B confirms that `@ApplicationScoped` constructor injection has zero per-request cost.
* **C: Header Only** (`/mock-jwt/header-only`) — Calls `resolveHeaderMap()` but does not parse headers or construct a HashMap. Returns a pre-built response. The difference C minus B isolates the Vert.x context resolution cost.

== Three-Layer Decomposition (Original)

The original three-layer decomposition used only the health, mock JWT, and JWT endpoints — before the ablation variants were introduced.

[cols="3,2,2", options="header"]
|===
|Component
|Latency (P50)
|Percentage

|**Shared infrastructure** (Docker, TLS, HTTP/2, Quarkus routing) — measured by health endpoint
|0.416ms
|21%

|**Header extraction + response serialization** (`resolveHeaderMap()`, `Authorization` parsing, `HashMap` construction, `ValidationResponse` JSON) — measured by mock endpoint minus health
|0.417ms
|21%

|**CDI producer chain + JWT validation** (`Instance.get()`, producer resolution, `createAccessToken()`, claims checking) — measured by JWT minus mock endpoint
|1.117ms
|**57%**
|===

**Total JWT P50**: 1.95ms = 0.416ms (shared) + 0.417ms (serialization) + 1.117ms (CDI + validation)

The five-layer decomposition refines the middle layer (0.417ms "header extraction + response serialization") into three sub-layers: JAX-RS POST routing (0.274ms), Vert.x context resolution (0.036ms), and Authorization parsing (0.003ms). The original 0.417ms and the refined 0.313ms (0.274 + 0.036 + 0.003) differ because measurements were taken in separate benchmark runs with different baseline latencies.

== JMH vs Integration Validation Cost

The JMH micro-benchmark measures isolated JWT library validation at 0.077ms (77µs). The mock endpoint experiment reveals the actual cost difference between JWT and mock is 1.087ms — **14.1x more** than the isolated library. This gap includes:

* **CDI `Instance<BearerTokenResult>` proxy resolution** — CDI creates and invokes the producer per request
* **`InjectionPoint` metadata extraction** — CDI inspects `@BearerToken` annotation parameters
* **`@Timed` micrometer instrumentation** — metrics recording overhead on every validation
* **`tokenValidator.createAccessToken()` under concurrency** — 50 concurrent connections competing for the lock-free cache, CPU cache line invalidation, memory barriers
* **`AccessTokenContent` construction** — real object allocation from parsed claims (vs JMH reusing pre-parsed data)

The previous (inferred) decomposition attributed 74% to "CDI/serialization" and only 4% to the JWT library. The measured data reverses this: header extraction and serialization cost only 16% (0.313ms across three sub-layers), while the CDI producer chain combined with JWT validation accounts for 57% (1.087ms).