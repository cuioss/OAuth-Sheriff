= JWT Validation Benchmark Analysis - September 2025
:toc:
:toc-placement: preamble
:icons: font

== Executive Summary

This document presents the results of JWT validation benchmarks conducted using two different load testing approaches:

1. **WRK Benchmark**: HTTP-based load testing with WRK (11.8-minute duration)
2. **Quarkus JMH Benchmark**: Java-based micro-benchmarking with JMH (8.5-minute duration)

Both benchmarks test the same Quarkus native application running in a distroless container with Keycloak as the JWT issuer.

== Test Environment

* **Platform**: macOS Darwin 24.6.0 (ARM64)
* **CPU**: 10 cores available
* **Java Version**: OpenJDK 21.0.7 (Temurin)
* **Quarkus**: Native compilation with Mandrel 23.1.8.0
* **Container**: Distroless image (111MB)
* **Keycloak**: Version 26.2.5
* **Test Date**: September 27, 2025

== Benchmark Results Comparison

[cols="3,2,2,3", options="header"]
|===
| Metric | WRK Benchmark | Quarkus JMH Benchmark | Source

3+^h| *Performance Summary* |

| Performance Score
| 83 (Grade B)
| 48 (Grade F)
| benchmark-data.json, key: overview.performanceScore

| Test Duration
| 11.8 minutes
| 8.5 minutes
| Build logs

4+^h| *JWT Validation Performance*

| Throughput
| 7,179.7 ops/s
| 8,117.5 ops/ms (8.1M ops/s)
| benchmark-data.json, key: benchmarks[].score

| Average Latency
| 5.0 ms
| 3.0 ms
| benchmark-data.json, key: benchmarks[].latency

| P99.9 Latency
| 21.48 ms
| 10.09 ms
| benchmark-data.json, key: benchmarks[].percentiles["99.9"]

| Error Rate
| 167.27% CV
| 0.38% error
| benchmark-data.json, key: benchmarks[].variabilityCoefficient/error

4+^h| *Health Check Performance*

| Throughput
| 3,361.93 ops/s
| 9,952.4 ops/ms (10.0M ops/s)
| benchmark-data.json, key: benchmarks[].throughput

| Average Latency
| 732 μs
| 2.2 ms
| benchmark-data.json, key: benchmarks[].latency

| P99.9 Latency
| 1.78 ms
| 8.39 ms
| benchmark-data.json, key: benchmarks[].percentiles["99.9"]

4+^h| *Health Live Check Performance (WRK only)*

| Throughput
| 2,604.98 ops/s
| N/A
| benchmark-data.json, key: benchmarks[].throughput

| Average Latency
| 940 μs
| N/A
| benchmark-data.json, key: benchmarks[].latency

| P99.9 Latency
| 2.44 ms
| N/A
| benchmark-data.json, key: benchmarks[].percentiles["99.9"]
|===

== Key Findings

=== Performance Characteristics

1. **JWT Validation Performance**
   - WRK shows 7,180 ops/s
   - JMH shows 8,118 ops/ms = 8.1 million ops/s - over 1000x higher throughput
   - Both tests use HTTP calls to the same endpoints
   - The massive difference is unexpected for HTTP-based tests
   - This suggests potential issues with measurement units or test configuration

2. **Health Check Performance**
   - WRK shows 3,362 ops/s
   - JMH shows 9,952 ops/ms = 10 million ops/s - nearly 3000x higher throughput
   - Both tests hit the same HTTP health endpoints
   - Such extreme differences for HTTP calls indicate a fundamental measurement discrepancy

3. **Startup Performance**
   - Native app starts in ~170-185ms consistently
   - Container adds ~1 second to total startup time

=== Issues Detected

==== WRK Test Issues
- High coefficient of variation (167%) for JWT validation
- Performance grade B (83/100)
- No errors reported in logs

==== JMH Test Issues
- **HTTP Timeout Exception** during healthCheckThroughput iteration 4 of fork 1
- Performance grade F (48/100) - likely due to the timeout failure
- GC allocation rate of 348 MB/sec indicates memory pressure

==== Log Warnings
- Gauge registration warning for http.server.active.connections metric
- JWT validation warnings about missing audience claims (expected for test environment)
- Keycloak SSL certificate warnings (using self-signed certificates)

== Recommendations

1. **Investigate JMH Timeout Issues**
   - The timeout during healthCheckThroughput suggests resource exhaustion
   - Consider reducing thread count (currently 24) or increasing timeout values

2. **Memory Optimization**
   - High GC allocation rate (348 MB/sec) needs investigation
   - Profile memory usage during JWT validation

3. **Connection Pool Tuning**
   - The 3x difference in health check throughput between WRK and JMH suggests connection management issues
   - WRK may need connection pool tuning or keep-alive settings adjustment
   - Consider investigating WRK's connection reuse patterns

4. **Benchmark Configuration**
   - The performance score difference (B vs F) needs investigation
   - Consider aligning test parameters between WRK and JMH
   - Both tests use HTTP, but connection strategies differ significantly

== Test Execution Details

=== WRK Benchmark
- **Full Maven Command**:
```bash
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk
```
- Duration: 11.8 minutes
- Result files: `benchmarking/benchmark-integration-wrk/target/benchmark-results/`

=== Quarkus JMH Benchmark
- **Full Maven Command**:
```bash
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-quarkus
```
- Duration: 8.5 minutes
- Configuration:
  * Threads: 24
  * Forks: 2
  * Warmup: 1 iteration × 3s
  * Measurement: 4 iterations × 12s
- Result files: `benchmarking/benchmark-integration-quarkus/target/benchmark-results/`

== Conclusion

Both benchmarks successfully completed with the Quarkus native application demonstrating:

- Sub-200ms native startup times
- JWT validation throughput in the thousands of operations per second
- Health check response times in the microsecond to millisecond range

However, the extreme differences in reported metrics (1000x-3000x) between WRK and JMH are concerning:

- Both tests supposedly use HTTP calls to the same endpoints
- 8.1 million HTTP requests/second for JWT validation seems unrealistic for a single instance
- 10 million HTTP requests/second for health checks is even more improbable
- This suggests either:
  * JMH is reporting in different units than expected (possibly operations, not full HTTP requests)
  * JMH might be measuring something different (method calls rather than HTTP calls)
  * There's a configuration error in one of the benchmarks
  * The benchmark results are being misinterpreted

Future testing should focus on:

1. **Verify measurement units** - Confirm whether JMH is really measuring ops/ms for HTTP calls
2. **Investigate the 1000x discrepancy** - This difference is too large to be explained by connection pooling alone
3. **Review benchmark code** - Ensure both benchmarks are actually making HTTP calls
4. **Resolve JMH timeout issues** - The timeout failures need investigation
5. **Standardize benchmark parameters** - Align thread counts, duration, and connection settings
6. **Validate results** - The reported throughput numbers need independent verification