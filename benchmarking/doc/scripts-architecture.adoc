= Scripts Architecture
:source-highlighter: highlight.js

Technical documentation for the benchmark processing scripts and their architecture.

== Overview

The benchmark processing workflow has been modularized into focused scripts that handle different aspects of the benchmark pipeline:

=== Core Scripts

. *process-all-benchmarks.sh* - Master orchestration script
+
* Coordinates all benchmark processing
* Handles both micro and integration benchmarks
* Creates processing status reports
* Entry point from GitHub Actions
. *process-micro-benchmarks.sh* - JMH micro benchmark processing
+
* Processes JMH benchmark results
* Creates performance badges
* Updates performance tracking
* Generates trend badges
. *process-integration-benchmarks.sh* - Integration benchmark processing
+
* Processes health check and JWT validation results
* Creates integration-specific badges
* Calculates JWT overhead metrics
* Prepares data for visualization
. *prepare-github-pages.sh* - GitHub Pages structure preparation
+
* Sets up unified directory structure
* Copies templates and resources
* Prepares data directory
* Ensures all visualization assets are in place

=== Supporting Scripts

* *create-unified-performance-badge.sh* - Creates all performance and informational badges (handles both micro and integration)
* *create-performance-tracking.sh* - Manages historical performance data
* *update-performance-trends.sh* - Updates trend analysis
* *create-unified-trend-badge.sh* - Creates consolidated trend badges

=== Utility Scripts

* *serve-local.sh* - Local HTTP server for testing (Python-based)
* *serve-local.js* - Local HTTP server for testing (Node.js-based)
* *prepare-step-metrics.sh* - Prepares step-by-step metrics data

=== Utility Libraries

* *lib/badge-utils.sh* - Common badge creation functions and color calculations
* *lib/metrics-utils.sh* - Common metric calculation and conversion utilities

== Usage

=== From GitHub Actions

The main entry point is called from `.github/workflows/benchmark.yml`:

[source,bash]
----
bash benchmarking/scripts/process-all-benchmarks.sh \
  benchmark-results \
  benchmarking/doc/templates \
  gh-pages \
  "${{ github.sha }}" \
  "$TIMESTAMP" \
  "$TIMESTAMP_WITH_TIME"
----

=== Local Testing

See link:local-testing.adoc[Local Testing Guide] for detailed instructions on testing visualizations locally.

== Output Structure

The scripts create a unified GitHub Pages structure:

----
gh-pages/
├── index-visualizer.html         # Micro benchmarks visualization
├── integration-index.html        # Integration benchmarks visualization
├── step-metrics-visualizer.html  # Step-by-step metrics
├── performance-trends.html       # Historical trends
├── data/                         # JSON data files
│   ├── jmh-result.json
│   ├── integration-result.json
│   ├── jwt-validation-metrics.json
│   └── performance-tracking.json
├── resources/                    # Shared CSS/JS resources
│   ├── common-styles.css
│   ├── navigation.js
│   └── ...
├── badges/                       # Generated badge JSON files
│   ├── performance-badge.json
│   ├── trend-badge.json
│   └── ...
└── processing-results.json       # Processing status report
----

== Key Features

. *Modular Design* - Each script has a focused responsibility
. *Error Handling* - Scripts track and report processing status
. *Badge Generation* - Automatic creation of shields.io compatible badges
. *Trend Analysis* - Historical performance tracking and trend calculation
. *Unified Navigation* - All pages share common navigation and resources