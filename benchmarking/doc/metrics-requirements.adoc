= Benchmark Metrics Requirements
:toc:
:toclevels: 3
:icons: font

== Overview

This document defines the metrics requirements for benchmark runs in the CUI JWT project.
All metrics MUST be collected from Prometheus after each benchmark run and stored for performance analysis.

== Metric Collection Requirements

=== Collection Timing
* Metrics MUST be collected for the exact duration of each benchmark
* Start time: When WRK benchmark begins sending requests
* End time: When WRK benchmark completes
* Resolution: 2-second intervals (matching Prometheus scrape interval)

=== Storage Format
* Each benchmark run produces: `<benchmarkName>-server-metrics.json`
* Location: `target/benchmark-results/prometheus/<benchmarkName>-server-metrics.json`
* Format: Structured JSON with aggregated and time-series data

== Required Metrics

=== 1. CPU Utilization

[cols="1,2,1,3"]
|===
| Metric | Description | Type | Notes

| `process_cpu_usage`
| CPU usage of the Quarkus process
| Gauge (0-1)
| The Java process CPU utilization

| `system_cpu_usage`
| CPU usage of the container/system
| Gauge (0-1)
| Container-level CPU (not host system)

| `system_cpu_count`
| Number of CPU cores available
| Gauge
| Available cores to the container
|===

==== Aggregation Required:
* Average CPU usage during test
* Peak CPU usage
* Standard deviation
* Percentiles (p50, p75, p90, p99)

=== 2. Memory Consumption

[cols="1,2,1,3"]
|===
| Metric | Description | Type | Notes

| `jvm_memory_used_bytes`
| Memory currently used
| Gauge
| Labeled by area (heap/nonheap)

| `jvm_memory_committed_bytes`
| Memory committed by JVM
| Gauge
| Memory guaranteed to be available

| `jvm_memory_max_bytes`
| Maximum memory available
| Gauge
| JVM max heap/nonheap limits

| `process_resident_memory_bytes`
| Resident Set Size (RSS)
| Gauge
| Actual physical memory used
|===

==== Aggregation Required:
* Average memory usage (heap, non-heap, total)
* Peak memory usage
* Memory growth rate (bytes/second)
* GC impact analysis

=== 3. JWT Validation Specific

[cols="1,2,1,3"]
|===
| Metric | Description | Type | Notes

| `cui_jwt_validation_success_operations_total`
| Successful JWT validations
| Counter
| Labeled by event_type

| `cui_jwt_validation_errors_total`
| JWT validation failures
| Counter
| Labeled by category, event_type

| `cui_jwt_bearer_token_validation_seconds_*`
| JWT validation duration
| Histogram
| Count, sum, max for timing
|===

==== Aggregation Required:
* Success rate
* Error categories distribution
* Cache hit rates (ACCESS_TOKEN_CACHE_HIT)
* Average validation time

=== 5. JVM Health Metrics

[cols="1,2,1,3"]
|===
| Metric | Description | Type | Notes

| `jvm_threads_live_threads`
| Current live threads
| Gauge
| Thread pool sizing

| `jvm_threads_daemon_threads`
| Daemon threads
| Gauge
| Background threads

| `jvm_gc_overhead`
| GC overhead percentage
| Gauge
| Time spent in GC

| `jvm_classes_loaded_classes`
| Loaded classes
| Gauge
| Class loading metrics
|===

==== Aggregation Required:
* Thread pool stability
* GC pressure indicators
* Class loading patterns

== Output Format Specification

=== File Structure: `<benchmarkName>-server-metrics.json`

[source,json]
----
{
  "benchmark": {
    "name": "healthCheck",
    "start_time": "2025-09-26T18:05:06Z",
    "end_time": "2025-09-26T18:05:38Z",
    "duration_seconds": 32
  },

  "resources": {
    "cpu": {
      "process": {
        "average_percent": 45.2,
        "peak_percent": 68.5,
        "std_dev": 12.3,
        "percentiles": {
          "p50": 44.0,
          "p75": 52.0,
          "p90": 61.0,
          "p99": 67.5
        }
      },
      "system": {
        "average_percent": 52.8,
        "peak_percent": 72.1
      },
      "cores_available": 4
    },

    "memory": {
      "heap": {
        "average_mb": 256.5,
        "peak_mb": 312.8,
        "final_mb": 298.2
      },
      "non_heap": {
        "average_mb": 64.2,
        "peak_mb": 68.5,
        "final_mb": 68.1
      },
      "rss": {
        "average_mb": 412.3,
        "peak_mb": 456.8
      },
      "gc": {
        "overhead_percent": 0.8,
        "collections": 12,
        "total_pause_ms": 145
      }
    },

    "threads": {
      "average": 42,
      "peak": 48,
      "final": 45,
      "daemon": 38
    }
  },

  "application": {
    "jwt_validations": {
      "total": 421584,
      "success": 421584,
      "errors": 0,
      "cache_hits": 380426,
      "cache_hit_rate_percent": 90.2,
      "average_validation_time_ms": 0.12
    },
    "error_categories": {
      // Distribution of error types if any
    }
  },

  "time_series": {
    // Optional: Include raw time-series data for detailed analysis
    "sampling_interval_seconds": 2,
    "data_points": 16,
    "metrics": {
      "cpu_usage": [...],
      "memory_usage_mb": [...]
    }
  }
}
----

== Implementation Notes

=== Metric Name Mapping

IMPORTANT: Prometheus metric names differ from what we expected. Use these actual names:

* `jvm_threads_live_threads` (NOT `jvm_threads_current`)
* `jvm_threads_daemon_threads` (NOT `jvm_threads_daemon`)
* `process_resident_memory_bytes` (if available)
* `http_server_requests_seconds_*` (histogram with count/sum/max)
* `system_cpu_usage` (container CPU, not host)
* `process_cpu_usage` (JVM process CPU)

=== Missing Metrics Handling

Some expected metrics may not be available:
* `jvm_gc_collection_seconds_*` - Not exported by Quarkus Micrometer
* Use `jvm_gc_overhead` instead for GC pressure analysis
* If RSS memory is not available, use heap + non-heap as approximation

=== Data Quality Checks

1. Verify time range matches benchmark duration
2. Check for data gaps (missing scrapes)
3. Validate metric values are within reasonable ranges
4. Flag any anomalies in the output

== Performance Debugging Insights

The collected metrics should enable debugging of:

1. **CPU Bottlenecks**: Is the service CPU-bound?
2. **Memory Pressure**: Is GC impacting performance?
3. **Thread Pool Exhaustion**: Are we running out of threads?
4. **Network I/O Limits**: Are we saturating network bandwidth?
5. **Cache Effectiveness**: How well is JWT caching working?
6. **Error Patterns**: What types of errors occur under load?
7. **Scalability Issues**: Does performance degrade non-linearly?
8. **Resource Leaks**: Does memory/thread count grow unbounded?

== Validation Requirements

Each metrics file MUST include:

* Non-zero request count
* CPU usage data
* Memory usage data
* Timestamp range matching benchmark duration
* Valid JSON structure
* All required summary statistics

== References

* Prometheus API Documentation: https://prometheus.io/docs/prometheus/latest/querying/api/
* Micrometer Metrics: https://micrometer.io/docs/concepts
* Quarkus Metrics Guide: https://quarkus.io/guides/micrometer