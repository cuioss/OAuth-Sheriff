= WRK-based JWT Integration Benchmarks
:toc: left
:toclevels: 3
:source-highlighter: highlight.js

High-performance HTTP benchmarking for JWT validation endpoints using WRK, addressing JMH limitations for REST API testing.

== Quick Start

[source,bash]
----
# Quick benchmark (30s duration, skip container lifecycle)
./mvnw clean verify -Pbenchmark,quick -pl benchmarking/benchmark-integration-wrk

# Full benchmark with container lifecycle management (3 minutes per benchmark)
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk

# Full benchmark - skip container start/stop (containers must be running)
./mvnw clean verify -Pbenchmark -Dskip.container.lifecycle=true -pl benchmarking/benchmark-integration-wrk

# Start containers manually for fast mode
cd cui-jwt-quarkus-parent/cui-jwt-quarkus-integration-tests
./scripts/start-integration-container.sh
----

== Why WRK?

* JMH benchmarks limited to 10-13k req/s due to framework overhead
* WRK achieves 20k+ req/s with lower latency
* Better connection pool management and HTTP/1.1 keep-alive
* Native C implementation with minimal overhead

== Architecture

=== Components

* **WRK Scripts** (`src/main/resources/wrk-scripts/`) - Lua scripts for request generation
* **Java Post-processor** (`WrkIntegrationRunner.java`) - Parses output, fetches metrics, generates reports
* **Maven Integration** - Lifecycle management via exec-maven-plugin

=== Benchmark Flow

1. Build native Quarkus application (optional with skip flag)
2. Start Docker containers (optional with skip flag)
3. Execute WRK benchmarks
4. Process results and fetch Quarkus metrics
5. Generate JSON reports
6. Dump application logs (always)
7. Stop containers (optional with skip flag)

== Configuration

=== Maven Profiles

[cols="2,3,3", options="header"]
|===
|Profile
|Description
|Properties Set

|`benchmark`
|Enables benchmarking
|`skip.benchmark=false`

|`quick`
|Quick testing mode (30s benchmarks)
|`wrk.duration=30s`, `skip.container.lifecycle=true`

|`autoscale`
|Auto-scaled load (8 threads, 200 connections)
|`wrk.threads=8`, `wrk.connections=200`

|`stress`
|High load testing (10 threads, 300 connections)
|`wrk.threads=10`, `wrk.connections=300`

|`max`
|Maximum load (may degrade, 12 threads, 400 connections)
|`wrk.threads=12`, `wrk.connections=400`
|===

==== Load Generation Profiles

The load generation profiles are designed to scale with different environments:

* **Default (4t/20c)**: Conservative baseline for CI environments (GitHub Actions has 2-4 vCPUs)
* **Autoscale (8t/200c)**: Optimal for typical development machines (8-10 cores)
* **Stress (10t/300c)**: High load for powerful local machines
* **Max (12t/400c)**: Breaking point testing

==== Environment-Specific Recommendations

[cols="2,2,2,3", options="header"]
|===
|Environment
|CPU Cores
|Recommended Profile
|Expected Throughput

|GitHub Actions (public repo)
|4 vCPU
|Default or `-Pautoscale`
|8-10k ops/s

|GitHub Actions (private repo)
|2 vCPU
|Default only
|5-7k ops/s

|Local Development (typical)
|8-10 cores
|`-Pautoscale` or `-Pstress`
|12-14k ops/s

|Local Development (high-end)
|12+ cores
|`-Pstress` or `-Pmax`
|14-16k ops/s
|===

Example usage:
[source,bash]
----
# Quick 30-second benchmarks (assumes containers are running)
./mvnw clean verify -Pbenchmark,quick -pl benchmarking/benchmark-integration-wrk

# Auto-scaled load for local development
./mvnw clean verify -Pbenchmark,autoscale -pl benchmarking/benchmark-integration-wrk

# Stress test with high load
./mvnw clean verify -Pbenchmark,stress -pl benchmarking/benchmark-integration-wrk

# Custom duration with specific profile
./mvnw clean verify -Pbenchmark,autoscale -Dwrk.duration=60s -pl benchmarking/benchmark-integration-wrk

# CI-friendly configuration (GitHub Actions)
./mvnw clean verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk
----

=== WRK Parameters

[source,xml]
----
<wrk.duration>180s</wrk.duration>         <!-- Test duration (default: 3 minutes, quick: 30s) -->
<wrk.threads>4</wrk.threads>              <!-- Number of threads -->
<wrk.connections>20</wrk.connections>     <!-- Concurrent connections -->
<wrk.timeout>2s</wrk.timeout>             <!-- Request timeout -->
<wrk.latency>true</wrk.latency>           <!-- Record latency distribution -->
----

=== Container Lifecycle Control

The `skip.container.lifecycle` property optimizes benchmark iteration:

[cols="2,3,3", options="header"]
|===
|Property Value
|Behavior
|Use Case

|`false` (default)
|Full lifecycle: build, start, stop containers
|CI/CD, first run, clean environment

|`true`
|Skip container operations, only run benchmarks
|Fast iteration, containers already running
|===

=== Service URLs

[source,xml]
----
<integration.service.url>https://localhost:10443</integration.service.url>
<keycloak.url>https://localhost:1443</keycloak.url>
<quarkus.metrics.url>https://localhost:10443</quarkus.metrics.url>
----

== Benchmarks

=== Health Check Benchmark

* **Endpoint**: `/q/health/live`
* **Script**: `health_check.lua`
* **Purpose**: Baseline performance without authentication
* **Expected**: 20,000+ req/s, <1ms latency

=== JWT Validation Benchmark

* **Endpoint**: `/api/v1/jwt/extract`
* **Script**: `jwt_benchmark.lua`
* **Purpose**: Real JWT processing performance
* **Expected**: 15,000+ req/s, 1-2ms latency

== Output

Results in `target/benchmark-results/`:

[cols="2,3", options="header"]
|===
|File
|Description

|`wrk-health-output.txt`
|Raw WRK output for health endpoint

|`wrk-health-results.json`
|Processed JSON report for health benchmark

|`wrk-jwt-output.txt`
|Raw WRK output for JWT endpoint

|`wrk-jwt-results.json`
|Processed JSON report for JWT benchmark

|`quarkus-logs.txt`
|Application logs from benchmark run
|===

=== JSON Report Format

[source,json]
----
{
  "timestamp": "2025-01-22T10:30:00Z",
  "benchmarkType": "wrk-integration",
  "serviceUrl": "https://localhost:10443",
  "performance": {
    "requests_per_second": 24184.90,
    "latency_avg_ms": 0.88,
    "total_requests": 365242,
    "duration_seconds": 15.10,
    "errors": 0
  },
  "systemMetrics": {
    // Quarkus metrics data
  }
}
----

== Performance Analysis

=== View Results

[source,bash]
----
# Check raw WRK output
cat target/benchmark-results/wrk-health-output.txt

# Analyze JSON reports
jq '.performance' target/benchmark-results/wrk-health-results.json

# Compare runs
diff <(jq '.performance' baseline/wrk-jwt-results.json) \
     <(jq '.performance' target/benchmark-results/wrk-jwt-results.json)
----

=== Performance Tuning

.Optimal Settings
[NOTE]
====
* **Threads**: 4 (matches typical CPU cores)
* **Connections**: 20 (avoids pool saturation)
* **Duration**:
  - Quick mode: 30s (fast iteration)
  - Full mode: 180s (stable results)
* **Timeout**: 2s (local testing)
====

.Connection Pool Saturation
[WARNING]
====
High connection counts (>50) can cause:

* Latency spike from 0.88ms to 39ms
* Throughput degradation
* Connection timeouts

Solution: Keep connections â‰¤ 20 for local testing
====

== Development

=== Running Tests

[source,bash]
----
# Unit tests for WRK result parser
./mvnw test -pl benchmarking/benchmark-integration-wrk

# Integration test with containers
./mvnw verify -Pbenchmark -pl benchmarking/benchmark-integration-wrk
----

=== Adding New Benchmarks

1. Create Lua script in `src/main/resources/wrk-scripts/`
2. Add Maven execution:

[source,xml]
----
<execution>
    <id>run-wrk-custom-benchmark</id>
    <phase>integration-test</phase>
    <goals><goal>exec</goal></goals>
    <configuration>
        <skip>${skip.benchmark}</skip>
        <executable>wrk</executable>
        <arguments>
            <argument>-t${wrk.threads}</argument>
            <argument>-c${wrk.connections}</argument>
            <argument>-d${wrk.duration}</argument>
            <argument>--timeout</argument>
            <argument>${wrk.timeout}</argument>
            <argument>--latency</argument>
            <argument>-s</argument>
            <argument>${wrk.script.dir}/custom.lua</argument>
            <argument>${integration.service.url}/api/custom</argument>
        </arguments>
        <outputFile>${wrk.results.dir}/wrk-custom-output.txt</outputFile>
    </configuration>
</execution>
----

3. Add post-processing execution for results

== Troubleshooting

=== Common Issues

[cols="2,3,2", options="header"]
|===
|Issue
|Cause
|Solution

|WRK not found
|Not installed
|`brew install wrk` (macOS)

|High latency (>10ms)
|Connection pool saturation
|Reduce connections: `-Dwrk.connections=10`

|Container startup fails
|Port conflict or Docker issue
|Check ports 10443, 1443 are free

|Missing Keycloak URL error
|System property not set
|Fixed in pom.xml, update module

|Timeout errors
|Service not ready
|Increase warmup time or check logs
|===

=== Debug Mode

[source,bash]
----
# Verbose Maven output
./mvnw clean verify -Pbenchmark -X -pl benchmarking/benchmark-integration-wrk

# Monitor containers
docker compose logs -f

# Check service health
curl -k https://localhost:10443/q/health
curl -k https://localhost:1443/realms/benchmark
----

== CI/CD Integration

=== GitHub Actions

[source,yaml]
----
- name: Install WRK
  run: |
    sudo apt-get update
    sudo apt-get install -y wrk

- name: Run WRK Benchmarks
  run: |
    ./mvnw clean verify -Pbenchmark \
      -pl benchmarking/benchmark-integration-wrk \
      -DskipTests

- name: Archive Results
  uses: actions/upload-artifact@v3
  with:
    name: wrk-benchmark-results
    path: benchmarking/benchmark-integration-wrk/target/benchmark-results/
----

=== Performance Regression Detection

[source,bash]
----
#!/bin/bash
BASELINE_RPS=$(jq '.performance.requests_per_second' baseline/wrk-jwt-results.json)
CURRENT_RPS=$(jq '.performance.requests_per_second' target/benchmark-results/wrk-jwt-results.json)

if (( $(echo "$CURRENT_RPS < $BASELINE_RPS * 0.9" | bc -l) )); then
  echo "Performance regression detected: ${CURRENT_RPS} < ${BASELINE_RPS} * 0.9"
  exit 1
fi
----

== Comparison with JMH Module

[cols="2,2,2", options="header"]
|===
|Aspect
|benchmark-integration-wrk (WRK)
|benchmark-integration-quarkus (JMH)

|Max throughput
|20k+ req/s
|10-13k req/s

|Latency accuracy
|Sub-millisecond
|Limited by JMH overhead

|Setup complexity
|Simple (WRK + Lua)
|Complex (JMH framework)

|Report format
|JSON + raw text
|JMH JSON + badges

|Best for
|HTTP endpoint testing
|Detailed JVM analysis
|===

== Future Enhancements

* [ ] JWT token generation with proper authentication
* [ ] Request body variations and payload testing
* [ ] WebSocket performance benchmarking
* [ ] Grafana dashboard integration
* [ ] Distributed load testing support
* [ ] Automatic performance regression alerts

== Related Documentation

* link:../doc/README.adoc[Main Documentation Hub]
* link:../benchmark-integration-quarkus/README.adoc[JMH Integration Benchmarks]
* link:../benchmark-library/README.adoc[Library Benchmarks]
* link:../../cui-jwt-quarkus-parent/cui-jwt-quarkus-integration-tests/README.adoc[Integration Test Infrastructure]