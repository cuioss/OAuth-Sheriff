= JWT Benchmark Analysis - Baseline Performance (July 30, 2025)
:source-highlighter: highlight.js

== Executive Summary

This analysis documents the baseline performance metrics for the JWT validation library as of July 30, 2025. These results establish the current performance standards for optimization efforts.

== Test Configuration

* *Token Pool*: 600 tokens (200 per issuer)
* *Cache Size*: 60 entries (10% of token pool)
* *Token Variation*: Custom data claims (50-250 chars)
* *JVM*: OpenJDK 64-Bit Server VM 21.0.7+6-LTS
* *Threads*: 100 concurrent threads
* *Iterations*: 3 measurement, 1 warmup

== Baseline Performance Metrics

=== ðŸ“Š Throughput Performance

|===
|Benchmark Type |Throughput (ops/s) |Per-Thread

|*Standard* |100,673 |1,007 ops/s/thread
|*Error Handling (0%)* |113,581 |1,136 ops/s/thread
|*Error Handling (50%)* |178,652 |1,787 ops/s/thread
|===

=== ðŸ“ˆ Response Time Metrics

|===
|Benchmark Type |Latency (Î¼s) |Notes

|*Standard Average* |860.66 |Average response time
|*Concurrent* |883.40 |Under concurrent load
|===

=== ðŸŽ¯ Component-Level Performance

|===
|Operation |P50 (Î¼s) |P95 (Î¼s) |P99 (Î¼s) |P99/P50 Ratio

|*Complete Validation* |52-84 |82-101 |112-31,675 |2.2x-377x
|*Signature Validation* |45-62 |69-71 |124-10,195 |2.1x-221x
|*Token Parsing* |3.7-6.1 |6.0-7.8 |6.5-14.0 |1.8x-3.4x
|*Claims Validation* |0.7-4.0 |1.2-5.7 |1.3-7.2 |1.6x-2.3x
|*Token Building* |2.0-7.8 |3.7-11.0 |4.6-14.0 |1.5x-2.3x
|*Header Validation* |0.1-0.5 |0.4-1.1 |0.5-1.6 |2.5x-5x
|*Cache Operations* |0.0-0.4 |0.2-0.8 |0.3-1.1 |2.8x-âˆž
|===

=== ðŸ“Š Variance Analysis

The benchmark results show varying P99 latencies across different workloads:

- *Complete Validation*: P99 ranges from 112Î¼s to 31,675Î¼s depending on workload (152Î¼s in average-time mode)
- *Signature Validation*: P99 spikes up to 10,195Î¼s in mixed token scenarios (124Î¼s in average-time mode)
- *Most Stable*: Token parsing and claims validation maintain consistent P99/P50 ratios < 4x
- *Mode Comparison*: Average-time mode shows stable P99 of 152Î¼s vs up to 31,675Î¼s in throughput mode (both using 100 threads)

== Key Performance Characteristics

. *Throughput Baseline*:
+
* Standard: 100,673 ops/s
* Error 0%: 113,581 ops/s
* Error 50%: 178,652 ops/s (best performance)

. *Latency Profile*:
+
* Average: 860.66Î¼s
* Concurrent: 883.40Î¼s
* P50 range: 52-84Î¼s (good median performance)

. *P99 Variance*:
+
* Complete validation P99: 112Î¼s to 31.7ms (152Î¼s in average-time mode)
* Signature validation P99: 124Î¼s to 10.2ms (stable 124Î¼s in average-time mode)
* High P99/P50 ratios in throughput mode vs stable average-time mode (both with 100 threads)

. *Component Performance*:
+
* Signature validation: Dominant component (45-62Î¼s P50)
* Token parsing: Consistent performance (3.7-6.1Î¼s P50)
* Cache operations: Minimal overhead (0.0-0.4Î¼s P50)
* Average-time mode shows more predictable P99 behavior than throughput mode

== Optimization Opportunities

=== High Priority

. *P99 Latency Spikes*: Address 31.7ms spikes in throughput mode (average-time mode shows stable 152Î¼s with same 100 threads)
. *Signature Validation*: Reduce 10.2ms+ P99 spikes in mixed scenarios (average-time mode shows stable 124Î¼s)
. *P99/P50 Ratios*: Target < 50x for predictable performance (average-time mode already achieves this)

=== Medium Priority

. *Throughput Enhancement*: Target >200k ops/s baseline (current: 100,673 ops/s)
. *Thread Efficiency*: Improve from 1,007 to >2,000 ops/s/thread
. *Average Latency*: Reduce from 860Î¼s to <500Î¼s

=== Low Priority

. *Cache Optimization*: Already performing well (0.0-0.4Î¼s P50)
. *Token Parsing*: Stable performance with minor P99 variance (6.5-14.0Î¼s)
. *Header Validation*: Small absolute times despite ratios

== Optimization Roadmap

=== High Priority - P99 Latency Reduction

* [ ] *Add Entropy Optimization Flags to Benchmarks*
** [ ] Add `-Djava.security.egd=file:/dev/./urandom` to regular benchmark profile
** [ ] Add `-Djava.security.egd=file:/dev/./urandom` to JFR benchmark profile
** [ ] Run complete benchmark suite with entropy flags
** [ ] Compare P99 results before/after entropy optimization
* [ ] *Complete Validation Stabilization* - *31.7ms P99 spikes (377x P99/P50)*
** [ ] Profile validation hotspots causing extreme spikes
* [ ] *Token Building Object Pooling* - *14.0Î¼s P99 spikes*
* [ ] *Claims Validation Optimization* - *7.2Î¼s P99 spikes*

=== Medium Priority - Throughput Enhancement

* [ ] *Throughput Optimization* - *Current: 100k ops/s baseline*
** [ ] Optimize synchronization points
** [ ] Reduce allocation rates
** [ ] Implement zero-copy token handling where possible
* [ ] *Thread Efficiency* - *Current: 1,007 ops/s/thread*
** [ ] Reduce thread contention
** [ ] Implement CompletableFuture-based validation pipeline

== Validation Methodology

=== Benchmark Commands

[source,bash]
----
# Standard benchmarks (from project root)
./mvnw verify -Pbenchmark -pl benchmarking/benchmark-core

# Component-level analysis
./mvnw verify -Pbenchmark-jfr -pl benchmarking/benchmark-core

# Thread scaling analysis
./mvnw verify -Pbenchmark -pl benchmarking/benchmark-core -Djmh.threads=1,50,100,150,200
----

== Conclusion

The JWT validation library baseline performance (July 30, 2025) shows:

*Current Strengths*:

. *Good median latency*: 52-84Î¼s P50 for complete validation
. *Error handling efficiency*: 178,652 ops/s with 50% error rate
. *Stable average-time mode performance*: P99 of 152Î¼s in average-time mode vs 31.7ms in throughput mode
. *Consistent core components*: Token parsing and claims validation show low variance

*Key Insights*:

. *Mode-dependent variance*: Throughput mode shows extreme P99 spikes while average-time mode remains stable (both with 100 threads)
. *Signature validation bottleneck*: 10.2ms P99 spikes in mixed scenarios vs 124Î¼s in average-time mode
. *Thread efficiency opportunity*: 1,007 ops/s/thread baseline performance

*Optimization Priorities*:

. *P99 latency reduction*: From 31.7ms to <5ms in throughput scenarios (High Priority)
. *Throughput enhancement*: From 100,673 to 200k ops/s (Medium Priority)
. *Thread efficiency*: From 1,007 to 2,000+ ops/s/thread (Medium Priority)
. *P99/P50 ratio*: From 377x to <50x for predictability (High Priority)

*Next Steps*:

. Investigate why average-time mode shows stable P99 while throughput mode spikes (both with 100 threads)
. Profile signature validation hotspots causing 10ms+ spikes
. Consider async architecture for 2x throughput gain

*Production Readiness*: The library shows good performance characteristics in average-time mode. The extreme P99 spikes appear specific to throughput mode optimization and may not impact typical production scenarios.