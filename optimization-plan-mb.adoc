= JWT Microbenchmark Optimization Plan
:toc: left
:toclevels: 3
:toc-title: Table of Contents
:sectnums:
:source-highlighter: highlight.js

== Action Items Checklist

=== **HIGHEST PRIORITY** - Benchmark Command Standardization ‚úÖ **COMPLETED**
- [x] Standardize benchmark execution to `./mvnw --no-transfer-progress clean verify -pl cui-jwt-benchmarking -Pbenchmark`
- [x] Update optimization-plan.adoc benchmark command references
- [x] Update .github/workflows/benchmark.yml to use -Pbenchmark profile
- [x] Verify -Pbenchmark profile exists and works correctly in cui-jwt-benchmarking/pom.xml
- [x] Audit all documentation for benchmark command consistency

=== Immediate Priority - Claims Validation Investigation üî¥ **CRITICAL PERFORMANCE ISSUES IDENTIFIED**
- [ ] Add JFR instrumentation to TokenClaimsValidator methods
- [ ] Profile individual claim validation steps (exp, nbf, aud, custom claims)
- [ ] Identify synchronous operations in claims processing
- [ ] Analyze memory allocation patterns during claim validation
- [ ] Profile date/time calculation overhead under concurrent load

==== **ULTRATHINK Analysis Results** - Root Cause Investigation Findings

**Critical Performance Bottlenecks Identified** (Source Code Analysis):

1. **üî¥ SYNCHRONOUS TIME OPERATIONS** - **Primary Suspect for 4,813x Variance**
   - **ExpirationValidator.java:65, 92, 97**: Multiple `OffsetDateTime.now()` calls per validation
   - **TokenContent.java:163**: Additional `OffsetDateTime.now()` in `isExpired()` method
   - **Impact**: System calls with high variance under concurrent load (200 threads)
   - **Problem**: Each token validation triggers 2-3 blocking time system calls
   - **Evidence**: Time-dependent operations are primary cause of tail latency variance

2. **üü° MEMORY ALLOCATION HOTSPOTS** - **Secondary Performance Impact**
   - **TokenBuilder.java:111**: `new HashMap<>()` for every token's claim extraction
   - **MandatoryClaimsValidator.java:83**: `new TreeSet<>()` for missing claims collection
   - **ClaimValue.java:26**: `new ArrayList<>()` for STRING_LIST claim types
   - **MandatoryClaimsValidator.java:153-175**: `StringBuilder` allocation in error handling
   - **Impact**: GC pressure causing tail latency spikes under concurrent load

3. **üü° COLLECTION OPERATIONS UNDER LOAD**
   - **AudienceValidator.java:129-137**: Stream operations with `anyMatch()` on collections
   - **TokenBuilder.java:114-132**: Map lookups and iterations during claim extraction
   - **Various validators**: Set containment checks that scale with memory pressure
   - **Impact**: Performance degradation under high concurrency (200 threads)

4. **üü° STRING PROCESSING OVERHEAD**
   - **Error message formatting**: Multiple string concatenations and formatting operations
   - **Log message preparation**: String formatting even when logging disabled at runtime
   - **ClaimName operations**: String-to-enum lookups and mappings
   - **Impact**: CPU overhead and string object allocation

5. **üü° OPTIONAL CHAIN OPERATIONS**
   - **TokenContent interface**: Multiple `Optional.map()` chains creating intermediate objects
   - **ClaimName.fromString()**: Optional-based lookups with object creation
   - **Impact**: Additional object allocation and method call overhead

**Specific Problem Locations**:

```java
// PRIMARY BOTTLENECK - Synchronous time operations
// ExpirationValidator.java:65, 92, 97
// OffsetDateTime.now()  - Called 2-3 times per token validation

// SECONDARY BOTTLENECKS - Memory allocation per token
// TokenBuilder.java:111
// Map<String, ClaimValue> claims = new HashMap<>();  - Per token

// MandatoryClaimsValidator.java:83  
// SortedSet<String> missingClaims = new TreeSet<>();  - Per validation
```

**Performance Impact Analysis**:
- **P50 (0.020ms)**: Fast path when no GC pressure, cached time operations
- **P99 (96.253ms)**: Extreme tail latency when GC pressure + time operation variance combine
- **4,813x variance**: Indicates combination of GC pauses + synchronous system calls
- **200-thread load**: Amplifies both memory pressure and time operation contention

**Next Investigation Priority**:
1. **Eliminate synchronous time operations** - Use cached time or async patterns
2. **Object pool for HashMap allocation** - Reuse claim maps to reduce GC pressure  
3. **Optimize audience validation** - Avoid stream operations under load
4. **Profile time operation variance** - Measure `OffsetDateTime.now()` distribution under load

=== High Priority - Tail Latency Analysis  
- [ ] Enable GC logging in microbenchmarks (-XX:+PrintGC)
- [ ] Profile thread contention in validation pipeline
- [ ] Compare single-thread vs 200-thread performance patterns
- [ ] Identify shared resource access causing contention
- [ ] Analyze object creation hotspots

=== Medium Priority - Signature Validation
- [ ] Profile RSA operations under concurrent load (default JDK provider)
- [ ] Analyze BigInteger.modPow performance characteristics
- [ ] Compare signature validation across different thread counts
- [ ] Investigate 187x P50-to-P99 variance root cause

=== Validation
- [ ] Re-run benchmarks: `./mvnw --no-transfer-progress clean verify -pl cui-jwt-benchmarking -Pbenchmark`
- [ ] Collect 100,000+ samples for statistical significance
- [ ] Validate claims validation P99 reduction
- [ ] Confirm overall validation latency improvement
- [ ] Document optimization techniques applied

== Performance Analysis Summary

**Module**: `cui-jwt-benchmarking` - JMH microbenchmarks, isolated JWT library performance

**Current Results** (65,075 samples, 200 threads):
- **Throughput**: 71,151 ops/sec (¬±258K variance)
- **Average Latency**: 2.6ms per operation

=== Critical Bottleneck: Claims Validation P99

|===
| Validation Step | P50 | P95 | P99 | P99/P50 Ratio
| **Claims Validation** | 0.020ms | 2.545ms | **96.253ms** | **4,813x** üî¥
| Complete Validation | 0.142ms | 7.689ms | 138.981ms | 979x
| Signature Validation | 0.083ms | 0.144ms | 15.562ms | 187x
| Token Parsing | 0.012ms | 0.021ms | 0.143ms | 12x ‚úÖ
| Header Validation | 0.001ms | 0.002ms | 0.003ms | 3x ‚úÖ
|===

**Key Finding**: Claims validation P99 (96ms) represents 69% of total validation P99 latency (139ms).

=== Error Handling Performance

**Fast-fail scenarios** (Œºs/op averages):
- Invalid signature: 785Œºs (fastest detection)
- Malformed tokens: 780Œºs  
- Valid tokens: 2,461Œºs
- Expired tokens: 2,896Œºs

**Observation**: Error percentage (0% vs 50%) has minimal performance impact.

== Root Cause Investigation Focus

=== Claims Validation Bottleneck Analysis

**Hypothesis**: 4,813x P50-to-P99 variance indicates:
1. **Expensive operations**: Complex claim validation logic
2. **Concurrency issues**: Shared resource contention
3. **Memory pressure**: Object allocation during validation
4. **Time calculations**: Date/time operations under load

**Investigation Required**:
- Profile specific claim validation methods
- Identify which claims cause high latency
- Analyze memory allocation patterns
- Check for blocking operations

=== Tail Latency Pattern Analysis

**Problem**: Extreme variance across all validation steps suggests systemic issues:
- Claims: 4,813x variance
- Complete validation: 979x variance  
- Signature validation: 187x variance

**Likely Causes**:
- GC pressure from object allocation
- Thread contention under 200-thread load
- Resource exhaustion at high concurrency

== Dismissed Optimization Approaches

=== JWT Token Caching
**Status:** ‚ùå DISMISSED - Processing time too high, caching won't solve core issue

**Reason:** With P99 latencies of 96ms for claims validation and 15ms for signature validation, caching cannot address the fundamental performance bottlenecks. The extreme variance (4,813x for claims validation) indicates algorithmic or concurrency issues that require direct optimization rather than avoidance through caching.

=== ES256 Algorithm Migration  
**Status:** ‚ùå DISMISSED - Integration tests use RS256, microbenchmarks follow suit

**Reason:** Integration test infrastructure is built around RS256. Microbenchmarks measure the same algorithm to ensure consistency. ES256 vs RS256 performance comparison is out of scope for core library optimization.

=== Hardware-Specific Optimizations
**Status:** ‚ùå DISMISSED - Focus on algorithmic improvements

**Reason:** CPU-specific optimizations (AES-NI, ARM crypto extensions) compromise portability and don't address the claims validation bottleneck which appears to be algorithmic rather than cryptographic.

=== Alternative JCA Providers in Microbenchmarks
**Status:** ‚ùå DISMISSED - Microbenchmarks use default JDK providers for consistency

**Reason:** BouncyCastle and other providers are integration test concerns. Microbenchmarks focus on core library performance with standard JDK providers to isolate library-specific bottlenecks.

=== Extended Measurement Duration
**Status:** ‚ùå DISMISSED - 4-second measurement sufficient for trend identification

**Reason:** Current setup provides 65,075 samples with clear P99 bottleneck identification. Extending measurement time won't change the 4,813x variance pattern in claims validation - investigation and optimization needed instead.

== Technical Context

**Microbenchmark Setup**:
- JMH 1.37, Java 21.0.7
- 200 threads, 3 iterations, 4s measurement, 1s warmup
- Default JDK cryptographic providers (no BouncyCastle)

**vs Integration Tests**:
- Microbenchmarks: 2.6ms average (pure library)
- Integration tests: 186.6ms P95 (with framework)
- **66x difference** = 97% framework overhead

**Focus**: Core library optimization separate from infrastructure optimization.