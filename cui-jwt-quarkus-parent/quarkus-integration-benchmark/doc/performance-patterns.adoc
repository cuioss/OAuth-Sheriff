= JWT Integration Benchmark Performance Patterns
:toc:
:toc-placement: preamble

This document describes expected performance patterns, measurement quality standards, and optimization guidelines for JWT integration benchmarks.

== Expected Performance Hierarchy

Based on fail-fast validation patterns, the following performance order is *expected and normal*:

=== 1. Error Token Performance (Fastest)

* *Expired tokens*: ~219 ops/s
* *Invalid tokens*: ~199 ops/s  
* *Missing auth headers*: ~202 ops/s

*Reason*: Fail-fast pattern - validation errors are detected early in the process before expensive cryptographic operations.

=== 2. Valid Token Performance (Slowest)

* *Valid access tokens*: ~194 ops/s
* *Valid refresh tokens*: ~164 ops/s
* *Valid ID tokens*: ~156 ops/s

*Reason*: Full validation pipeline including signature verification, claims validation, and token parsing.

=== 3. Token Type Performance Differences

* *Access tokens*: Fastest valid token type (most optimized path)
* *Refresh tokens*: ~15% slower than access tokens
* *ID tokens*: ~20% slower than access tokens

*Reason*: Different claim sets and validation requirements per token type.

== Performance Anomaly Guidelines

=== ✅ Normal Patterns (DO NOT Flag as Issues)

* Error tokens performing better than valid tokens
* Expired tokens having highest throughput
* Invalid tokens outperforming valid tokens
* ID/Refresh tokens slower than access tokens

=== ⚠️ Investigate These Patterns

* Valid tokens performing better than error tokens
* Extremely high variance (>30% error margin)
* SingleShot measurements with 100% error
* Throughput significantly below expected ranges

== Measurement Quality Standards

=== Acceptable Error Margins

* *Micro-benchmarks*: ≤15% error margin
* *Integration benchmarks*: ≤20% error margin (network overhead)
* *Latency measurements*: ≤15% error margin

=== Unacceptable Measurements

* *>30% error margin*: Indicates measurement instability
* *100% error margin*: Completely unreliable, remove benchmark
* *Negative confidence intervals*: JMH configuration issue

== Configuration Optimizations Applied

=== Timing Improvements

* Integration tests: 3s measurement/warmup (vs 2s for micro-benchmarks)
* Longer windows compensate for network latency variance
* 3 iterations provide better statistical confidence

=== Benchmark Removals

* SingleShot mode removed due to 100% error margin
* Mode.All removed from concurrent benchmarks to reduce noise

=== LogManager Configuration

* Added `-Djava.util.logging.manager=org.jboss.logmanager.LogManager`
* Eliminates LogManager initialization conflicts
* Ensures consistent logging behavior during benchmarks

== Achieved Improvements

=== Variance Reductions

* `benchmarkConcurrentHealthCheck`: 25% → 6% (76% variance reduction)
* `validateMixedTokens`: 27% → 15% (44% variance reduction)
* `benchmarkHealthCheck`: 12% → 3% (75% variance reduction)

=== Configuration Verification

* ✅ 3s timing windows applied correctly
* ✅ LogManager errors eliminated
* ✅ Most benchmarks now ≤15% error margin
* ✅ Expected fail-fast patterns maintained