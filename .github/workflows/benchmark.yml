name: Performance Benchmark

on:
  pull_request:
    branches: [ "main" ]
    types: [ closed ]
  push:
    tags: [ "*" ]
  workflow_dispatch:

# Declare default permissions as read only
permissions: read-all

# Prevent concurrent benchmark runs to avoid interference
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel in-progress runs as benchmarks are expensive

jobs:
  benchmark:
    name: Run JMH Benchmarks
    runs-on: ubuntu-latest
    # Only run on merged PRs, not just closed ones
    if: github.event_name != 'pull_request' || github.event.pull_request.merged == true
    # Add timeout to prevent long-running jobs (increased for integration benchmarks)
    timeout-minutes: 45
    permissions:
      # Needed to upload artifacts
      contents: write

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@ec9f2d5744a09debf3a187a3f4f675c53b671911 # v2.13.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          fetch-depth: 0  # Fetch all history for proper versioning

      - name: Set up JDK 21
        uses: actions/setup-java@dded0888837ed1f317902acf8a20df0ad188d165 # v5.0.0
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: maven
      
      - name: Cache npm packages
        uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Build cui-jwt-validation
        run: |
          # Build validation module first to ensure test artifact is available for benchmarking
          ./mvnw --no-transfer-progress clean install -DskipTests

      - name: Run Micro Benchmarks
        run: |
          # Run micro benchmarks using configuration from pom.xml
          # The benchmarks now automatically generate artifacts in target/benchmark-results
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-library -Pbenchmark
          
          # Verify artifacts were generated
          echo "ðŸ“Š Micro benchmark artifacts generated:"
          ls -la benchmarking/benchmark-library/target/benchmark-results/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.7.1

      - name: Run Integration Benchmarks
        run: |
          # Run integration benchmarks with native image using profile that includes container startup
          # The benchmarks now automatically generate artifacts in target/benchmark-results
          echo "ðŸš€ Running integration benchmarks with native Quarkus..."
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-integration-quarkus -Pbenchmark-testing
          
          # Verify artifacts were generated
          echo "ðŸ“Š Integration benchmark artifacts generated:"
          ls -la benchmarking/benchmark-integration-quarkus/target/benchmark-results/

      - name: Combine Benchmark Artifacts
        run: |
          # Create combined gh-pages directory with separate subdirectories for each benchmark type
          mkdir -p gh-pages
          mkdir -p gh-pages/micro
          mkdir -p gh-pages/integration
          mkdir -p gh-pages/badges
          
          # Copy micro benchmark artifacts to micro subdirectory
          if [ -d "benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready" ]; then
            echo "ðŸ“¦ Copying micro benchmark artifacts..."
            cp -r benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/* gh-pages/micro/
            # Copy micro badges to root badges directory
            if [ -d "benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/badges" ]; then
              cp benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/badges/performance-badge.json gh-pages/badges/ 2>/dev/null || true
              cp benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/badges/trend-badge.json gh-pages/badges/ 2>/dev/null || true
              cp benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/badges/last-run-badge.json gh-pages/badges/ 2>/dev/null || true
            fi
          fi
          
          # Copy integration benchmark artifacts to integration subdirectory
          if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready" ]; then
            echo "ðŸ“¦ Copying integration benchmark artifacts..."
            cp -r benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/* gh-pages/integration/
            # Copy integration badges to root badges directory
            if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/badges" ]; then
              cp benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/badges/integration-performance-badge.json gh-pages/badges/ 2>/dev/null || true
              cp benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/badges/integration-trend-badge.json gh-pages/badges/ 2>/dev/null || true
            fi
          fi
          
          # Create main index.html that links to both benchmark types
          cat > gh-pages/index.html <<'EOF'
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CUI JWT Benchmarks</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif; margin: 40px auto; max-width: 1200px; padding: 0 20px; }
        h1 { color: #333; border-bottom: 2px solid #e1e4e8; padding-bottom: 10px; }
        .benchmark-cards { display: grid; grid-template-columns: repeat(auto-fit, minmax(400px, 1fr)); gap: 20px; margin-top: 30px; }
        .card { background: white; border: 1px solid #e1e4e8; border-radius: 8px; padding: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .card h2 { margin-top: 0; color: #0366d6; }
        .metrics { display: grid; gap: 10px; margin: 20px 0; }
        .metric { display: flex; justify-content: space-between; padding: 8px; background: #f6f8fa; border-radius: 4px; }
        .btn { display: inline-block; padding: 10px 20px; background: #0366d6; color: white; text-decoration: none; border-radius: 4px; margin-top: 15px; }
        .btn:hover { background: #0256c7; }
        .badge { vertical-align: middle; margin-left: 10px; }
    </style>
</head>
<body>
    <h1>CUI JWT Performance Benchmarks</h1>
    <p>Comprehensive benchmarking suite for JWT validation library</p>
    
    <div class="benchmark-cards">
        <div class="card">
            <h2>Micro Benchmarks</h2>
            <p>Low-level performance tests for core JWT validation operations</p>
            <div class="metrics">
                <div class="metric">
                    <span>Performance:</span>
                    <img class="badge" src="badges/performance-badge.json" alt="Performance" />
                </div>
                <div class="metric">
                    <span>Trend:</span>
                    <img class="badge" src="badges/trend-badge.json" alt="Trend" />
                </div>
            </div>
            <a href="micro/" class="btn">View Micro Benchmarks â†’</a>
        </div>
        
        <div class="card">
            <h2>Integration Benchmarks</h2>
            <p>End-to-end performance tests with Quarkus native container</p>
            <div class="metrics">
                <div class="metric">
                    <span>Performance:</span>
                    <img class="badge" src="badges/integration-performance-badge.json" alt="Integration Performance" />
                </div>
                <div class="metric">
                    <span>Trend:</span>
                    <img class="badge" src="badges/integration-trend-badge.json" alt="Integration Trend" />
                </div>
            </div>
            <a href="integration/" class="btn">View Integration Benchmarks â†’</a>
        </div>
    </div>
    
    <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #e1e4e8; color: #586069;">
        <p>Last updated: <script>document.write(new Date().toISOString())</script></p>
    </footer>
</body>
</html>
EOF
          
          # Add metadata
          echo "{ \"timestamp\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\", \"commit\": \"${{ github.sha }}\" }" > gh-pages/metadata.json
          
          echo "ðŸ“Š Combined artifacts structure:"
          ls -la gh-pages/
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-results
          path: gh-pages/
          retention-days: 90  # Keep results for 90 days

      - name: Deploy to cuioss.github.io
        uses: JamesIves/github-pages-deploy-action@6c2d9db40f9296374acc17b90404b6e8864128c8 # v4.7.3
        with:
          folder: gh-pages
          repository-name: cuioss/cuioss.github.io
          target-folder: cui-jwt/benchmarks
          branch: main
          token: ${{ secrets.PAGES_DEPLOY_TOKEN }}
