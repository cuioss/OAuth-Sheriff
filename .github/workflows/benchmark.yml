name: Performance Benchmark

on:
  pull_request:
    branches: [ "main" ]
    types: [ closed ]
  push:
    tags: [ "*" ]
  workflow_dispatch:

# Declare default permissions as read only
permissions: read-all

# Prevent concurrent benchmark runs to avoid interference
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel in-progress runs as benchmarks are expensive

jobs:
  benchmark:
    name: Run JMH Benchmarks
    runs-on: ubuntu-latest
    # Only run on merged PRs, not just closed ones
    if: github.event_name != 'pull_request' || github.event.pull_request.merged == true
    # Add timeout to prevent long-running jobs (increased for integration benchmarks)
    timeout-minutes: 45
    permissions:
      # Needed to upload artifacts
      contents: write

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@ec9f2d5744a09debf3a187a3f4f675c53b671911 # v2.13.0
        with:
          egress-policy: audit

      - name: Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          fetch-depth: 0  # Fetch all history for proper versioning

      - name: Set up JDK 21
        uses: actions/setup-java@dded0888837ed1f317902acf8a20df0ad188d165 # v5.0.0
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: maven

      - name: Build cui-jwt-validation
        run: |
          # Build validation module first to ensure test artifact is available for benchmarking
          ./mvnw --no-transfer-progress clean install -DskipTests

      - name: Run Micro Benchmarks
        run: |
          # Run micro benchmarks using configuration from pom.xml
          # The benchmarks now automatically generate artifacts in target/benchmark-results
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-library -Pbenchmark
          
          # Verify artifacts were generated
          echo "ðŸ“Š Micro benchmark artifacts generated:"
          ls -la benchmarking/benchmark-library/target/benchmark-results/

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3.7.1

      - name: Run Integration Benchmarks
        run: |
          # Run integration benchmarks with native image using profile that includes container startup
          # The benchmarks now automatically generate artifacts in target/benchmark-results
          echo "ðŸš€ Running integration benchmarks with native Quarkus..."
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-integration-quarkus -Pbenchmark-testing
          
          # Verify artifacts were generated
          echo "ðŸ“Š Integration benchmark artifacts generated:"
          ls -la benchmarking/benchmark-integration-quarkus/target/benchmark-results/

      - name: Combine Benchmark Artifacts
        run: |
          # Create combined gh-pages directory from both benchmark runs
          mkdir -p gh-pages
          mkdir -p gh-pages/data
          mkdir -p gh-pages/badges
          mkdir -p gh-pages/api
          
          # Copy micro benchmark artifacts (already in GitHub Pages structure)
          if [ -d "benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready" ]; then
            echo "ðŸ“¦ Copying micro benchmark artifacts..."
            cp -r benchmarking/benchmark-library/target/benchmark-results/gh-pages-ready/* gh-pages/
          fi
          
          # Merge integration benchmark artifacts (preserve existing structure)
          if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready" ]; then
            echo "ðŸ“¦ Merging integration benchmark artifacts..."
            # Ensure directories exist before copying
            if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/data" ]; then
              cp benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/data/*integration* gh-pages/data/ 2>/dev/null || true
            fi
            if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/badges" ]; then
              cp benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/badges/*integration* gh-pages/badges/ 2>/dev/null || true
            fi
            # Merge API files
            if [ -d "benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/api" ]; then
              cp benchmarking/benchmark-integration-quarkus/target/benchmark-results/gh-pages-ready/api/* gh-pages/api/ 2>/dev/null || true
            fi
          fi
          
          # Add metadata
          echo "{ \"timestamp\": \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\", \"commit\": \"${{ github.sha }}\" }" > gh-pages/metadata.json
          
          echo "ðŸ“Š Combined artifacts structure:"
          ls -la gh-pages/
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: benchmark-results
          path: gh-pages/
          retention-days: 90  # Keep results for 90 days

      - name: Deploy to cuioss.github.io
        uses: JamesIves/github-pages-deploy-action@6c2d9db40f9296374acc17b90404b6e8864128c8 # v4.7.3
        with:
          folder: gh-pages
          repository-name: cuioss/cuioss.github.io
          target-folder: cui-jwt/benchmarks
          branch: main
          token: ${{ secrets.PAGES_DEPLOY_TOKEN }}
