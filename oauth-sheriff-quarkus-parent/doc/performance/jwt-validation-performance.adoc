= JWT Validation Performance
:toc: left
:toclevels: 3
:toc-title: Table of Contents
:sectnums:
:source-highlighter: highlight.js

== Purpose

This document defines the current JWT validation performance characteristics, baselines, and analysis for the CUI OAuth Sheriff Quarkus integration. It provides technical specifications for performance metrics, latency decomposition, and optimization guidance.

== Related Documentation

* xref:native-optimization-guide.adoc[Native Optimization Guide] - GraalVM build configuration and optimization settings
* xref:jfr-profiling-guide.adoc[JFR Profiling Guide] - Performance analysis tools and methods
* xref:graalvm-rsa-optimization-analysis.adoc[GraalVM RSA Analysis] - Cryptographic performance analysis
* link:../../../benchmarking/doc/Analysis-01.2026-Integration.adoc[Integration Benchmark Analysis] - Full benchmark data tables
* link:../../../benchmarking/doc/Analysis-01.2026-JFR-Profiling.adoc[JFR Profiling Analysis] - CPU hotspot analysis
* link:../../../benchmarking/doc/Analysis-01.2026-Latency-Decomposition.adoc[Latency Decomposition] - Five-layer latency breakdown

== Performance Baselines (January 2026)

=== System Configuration

* **Platform**: Apple M4, 10 CPU cores, 32 GB RAM
* **Runtime**: Mandrel jdk-25 native image
* **Framework**: Quarkus 3.27.2 (LTS)
* **Container**: Docker with Keycloak for token issuance

=== Current Performance Summary

[cols="3,2,2,2", options="header"]
|===
| Endpoint | Throughput | P50 Latency | P99 Latency

| **JWT Validation**
| 22,700-24,300 ops/s
| 1.91ms
| 4.78ms

| **Health Check**
| 64,900-89,900 ops/s
| 0.510ms
| 1.37ms

| **JWT Library (JMH)**
| 159,100 ops/s
| 77µs
| N/A
|===

NOTE: JWT validation is 4.55x slower than health check baseline due to CDI producer chain, JWT parsing, and signature verification overhead.

=== Connection Scaling Performance

[cols="1,2,2,2", options="header"]
|===
| Connections | JWT ops/s | Health ops/s | JWT/Health Ratio

| 50
| 24,319
| 89,932
| 3.70x

| 100
| 23,428
| 75,055
| 3.20x

| 200
| 23,190
| 68,219
| 2.94x

| 300
| 22,718
| 64,947
| 2.86x
|===

JWT validation throughput remains stable (22.7-24.3K ops/s) across all connection levels, demonstrating excellent scalability.

== Latency Decomposition

=== Measured Endpoints (Ablation Study)

[cols="2,2,2", options="header"]
|===
| Endpoint | P50 Latency | Throughput

| Health (`/q/health/live`)
| 0.510ms
| 64,947 ops/s

| Mock JWT (`/mock-jwt/validate`)
| 0.823ms
| 46,800 ops/s

| JWT (`/jwt/validate`)
| 1.91ms
| 23,051 ops/s
|===

The **Mock JWT endpoint** performs identical HTTP processing (CDI injection, header extraction, JSON serialization) but skips JWT validation. This directly measures the validation cost.

=== Latency Breakdown

[cols="2,2,2,2", options="header"]
|===
| Component | How Measured | Latency | Percentage

| Shared Infrastructure
| Health endpoint
| 0.510ms
| 27%

| Framework Overhead (POST, JAX-RS, Jackson)
| Mock JWT − Health
| 0.313ms
| 16%

| **CDI Producer Overhead**
| (JWT − Mock JWT) − JMH
| **~1.01ms**
| **53%**

| JWT Library (parsing + RSA)
| JMH microbenchmark
| 0.077ms
| 4%
|===

**Total**: 0.510 + 0.313 + 1.01 + 0.077 = 1.91ms ✓

The CDI producer overhead (1.01ms) includes `Instance<BearerTokenResult>.get()`, `InjectionPoint` inspection, `@Timed` instrumentation, and concurrency effects under 50 connections.

=== Why JWT is Slower than Health

The **1.4ms difference** between JWT (1.91ms) and Health (0.510ms) breaks down into three components:

[cols="2,2,2", options="header"]
|===
| Component | Latency | Share of 1.4ms

| Framework Overhead (POST, JAX-RS, Jackson)
| 0.313ms
| 22%

| **CDI Producer Overhead**
| **~1.01ms**
| **72%**

| JWT Library (parsing + RSA)
| 0.077ms
| 6%
|===

**Total**: 0.313 + 1.01 + 0.077 = **1.4ms** ✓

=== Key Insight

The **Mock JWT endpoint** replicates the full HTTP path but skips `tokenValidator.createAccessToken()`. Combined with JMH microbenchmarks, this separates CDI overhead from JWT library cost:

* **Health → Mock JWT** (0.313ms): Framework overhead
* **Mock JWT → JWT** (1.087ms): CDI producer + JWT library
* **JMH benchmark** (0.077ms): JWT library in isolation
* **CDI producer overhead**: 1.087ms − 0.077ms = **~1.01ms**

The CDI overhead includes:

* `Instance<BearerTokenResult>.get()` proxy resolution
* `InjectionPoint` metadata extraction for `@BearerToken` annotation
* `@Timed` micrometer instrumentation
* Concurrency effects (50 connections, cache contention)

NOTE: The JWT library (77µs) is only **6%** of the latency gap. The dominant cost (**72%**) is CDI producer overhead.

See link:../../../benchmarking/doc/Analysis-01.2026-Latency-Decomposition.adoc[Latency Decomposition Analysis] for detailed methodology.

== JWT Library Performance (JMH Analysis)

=== Component-Level Timing

[cols="2,2,2", options="header"]
|===
| Component | Time | Share of JWT Processing

| RSA Signature Verification
| 68µs
| **88%**

| Token Parsing
| 4.3µs
| 6%

| Cache Operations
| 0.1µs
| <1%

| Other
| ~4.6µs
| 6%
|===

=== RSA Performance Verdict

**RSA signature verification at 68µs is excellent** and NOT a performance bottleneck. Historical claims of 230ms RSA overhead were based on incorrect benchmark methodology.

JFR profiling confirms BigInteger.modPow() accounts for only **1% of CPU samples** during load testing. The dominant CPU consumer is **TLS encryption at 89%** (HTTPS overhead, not JWT-specific).

See link:../../../benchmarking/doc/Analysis-01.2026-JFR-Profiling.adoc[JFR Profiling Analysis] for full CPU hotspot data.

== Algorithm Performance Characteristics

=== Signature Algorithm Comparison

[cols="2,2,2,3", options="header"]
|===
| Algorithm | Type | Security Level | Performance Notes

| RS256/384/512
| RSA
| 2048-bit
| 68µs - Current default, excellent performance

| ES256/384/512
| ECDSA
| 256-384-bit curves
| Expected faster, marginal benefit over current RSA

| Ed25519/Ed448
| EdDSA
| Curve25519/448
| Fastest, smaller signatures
|===

=== Algorithm Migration Guidance

**No urgent algorithm migration required.** With RSA at 68µs (88% of 77µs total library processing), algorithm choice should be driven by:

1. **Standards compliance** - What do your identity providers support?
2. **Token size** - EdDSA provides smaller signatures for bandwidth-constrained scenarios
3. **Key management** - RSA key rotation workflows may differ from ECDSA/EdDSA

Migration to ECDSA/EdDSA would provide marginal improvement (~50µs savings) representing only 2.5% of total request latency.

== Native Image Performance

=== Build Metrics

[cols="2,2,3", options="header"]
|===
| Metric | Value | Notes

| Startup Time
| 0.172s
| Excellent for serverless/container workloads

| Image Size (Distroless)
| ~104MB
| Production deployment target

| Image Size (JFR-enabled)
| ~187MB
| Includes UBI runtime for profiling

| Memory (RSS)
| ~50-128MB peak
| Efficient for 512MB container limit

| Build Time
| ~4m 30s
| With Mandrel jdk-25 container build
|===

=== GraalVM/Mandrel 25 Features

* **WP-SCCP**: Whole-Program Sparse Conditional Constant Propagation (enabled by default)
* **ML Profile Inference**: 1-3% performance boost via GraalNN
* **JCMD Support**: Native images now support `jcmd` for runtime diagnostics
* **JFR Improvements**: New `jdk.ObjectAllocationSample` event

== Performance Targets

=== Current Achievement Status

[cols="2,2,2,2", options="header"]
|===
| Metric | Target | Actual | Status

| JWT Throughput
| >10,000 ops/s
| 22,700+ ops/s
| ✅ Exceeds 2.3x

| JWT P50 Latency
| <5ms
| 1.91ms
| ✅ Exceeds by 2.6x

| Health Baseline
| >50,000 ops/s
| 64,900+ ops/s
| ✅ Exceeds 1.3x

| Memory Usage
| <90% of 512MB
| ~128MB peak
| ✅ 25% utilization

| Startup Time
| <1s
| 0.172s
| ✅ Exceeds 5.8x
|===

=== Performance Optimization Priorities

If further optimization is needed:

1. **CDI Producer Chain** (highest impact) - Consider `@RequestScoped` caching of `BearerTokenResult`
2. **TLS Session Resumption** - Verify session cache effectiveness
3. **Connection Pooling** - Monitor Netty buffer allocation under extreme load

== Benchmark Execution

=== Standard Benchmark Commands

[source,bash]
----
# Build and run integration benchmarks
cd oauth-sheriff-quarkus-parent/oauth-sheriff-quarkus-integration-tests
../../mvnw clean verify -Pintegration-tests

# Run JMH microbenchmarks
cd benchmarking/benchmark-core
../../mvnw clean verify -Pbenchmark

# JFR profiling with volume mount
docker compose -f docker-compose.yml -f docker-compose.jfr.yml up -d
----

=== Performance Regression Detection

* **Regression threshold**: >10% throughput loss
* **Improvement threshold**: >5% throughput gain
* **Memory threshold**: <90% container limit
* **CPU utilization target**: ≥90% under load

== See Also

* xref:native-optimization-guide.adoc[Native Optimization Guide]
* xref:jfr-profiling-guide.adoc[JFR Profiling Guide]
* xref:graalvm-rsa-optimization-analysis.adoc[GraalVM RSA Analysis]
* xref:graalvm-enterprise-optimization-options.adoc[Enterprise Optimization Options]
